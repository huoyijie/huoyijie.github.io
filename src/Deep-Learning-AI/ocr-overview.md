## 1.需求方主要诉求

* 可处理多样性版式
* 可处理不清晰图片(人眼可分辨)
* 成功率高
* 最核心的是提取清单列表中项目名称、金额、医保类型字段(分析所得，暂不明确)，用以计算可报销金额
* 识别结果结构化程度(暂不明确)，识别结果可对接后续的报销系统

## 2.OCR 分级

* 1级: 按照从上到下、从左到右依次识别所有文本
* 2级: 简单字段信息提取(如姓名、年龄等。表格不行)/表格识别（把图中的表格转换为excel可编辑格式）
* 3级: 基于 LLM + 视觉的对话多模态模型，通过 Prompt 的方式提取指定信息

第1级不满足需求

第2级中简单字段提取可以，复杂多变的表格信息结构化提取需要非常复杂的后处理程序，估计不太现实。而表格识别虽然可以转换成 excel 可编辑格式，但是一般训练针对的是论文、文档或者网页中表格，表格图片质量高。当前场景拍摄的打印清单等票据与训练数据差距非常大，需要微调模型，需要准备大量高质量数据，可以做到什么程度暂时不清晰

第3级通过对话方式提取图片中信息，效率低，且不容易对接报销系统。且对表格列表提取貌似支持不好，比如提取图片中所有药品名称列表

## 3.识别成功率主要影响因素

### 3.1版式多样

* 全国各地区不同医院门诊纸质发票、电子发票
* 全国各地区不同医院门诊纸质清单、电子清单

### 3.2打印扫描

* 打印字体、字号、墨色多样
* 字迹由于着墨量不同，有晕染、侵蚀、模糊不清、缺墨字迹看不清、墨水多笔画凑在一起、随机的墨点干扰等
* 纸质票据打印串行、出格等不规范情况非常多
* 纸张褶皱
* 遮挡（其他纸张）
* 遮盖（如公章）
* 存在手写体(不同的人手写字差异大，可能有些人的的申请表识别成功率低)

### 3.3拍摄

* 拍摄方向(可通过模型预调整)
* 存在文档扭曲、倾斜、透视变形等几何变换
* 背景干扰（如其他带字纸张）（可尝试通过蒙版框出核心识别区域）
* 拍摄模糊
* 光照反射、明暗、阴影

### 3.4微调/训练数据集(重要)

* **合成数据(需要收集尽可能多的不同地区和医院的不同票据格式，尽可能生成更全面的合成数据)**
* **真实数据(可能需要大量标注，标注格式和数量还需要实验确认)**

制作高质量的数据集非常关键

## 4.候选技术方案

| 模型   | 问题   |
|------------|------------|
| Got-ocr2.0| 基座模型对字迹不清晰、扭曲变形、印章遮挡、手写字等等效果不好|
| PaddleOCR/PaddleX| 暂不清晰|

| 方案   | 问题   |
|------------|------------|
| 微调模型，把表格识别为Excel| 需用户可手动编辑调整Excel，并基于Excel进行核对计算，不同版式的Excel格式不一样|
| 微调模型，结构化提取关键信息| 目前还属于正在积极研究的领域，主要问题是版式丰富多样，能做到什么程度需要实验尝试。|

通过 Web 各种工具深度结合定制模型来实现更好的体验，极大简化计算报销金额的任务(需求暂不明确)。